{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Wimsey \ud83d\udd0d","text":"<p>Wimsey is a lightweight, flexible and fully open-source data contract library. It's designed to let you:</p> <ul> <li>Bring your own dataframe library: Wimsey is built on top of Narwhals so your tests are carried out natively in your own dataframe library (including Pandas, Polars, Dask, CuDF, Rapids, Arrow and Modin)</li> <li>Bring your own contract format: Write contracts in yaml, json or python - whichever you prefer!</li> <li>Ultra Lightweight: Built for fast imports and minimal overwhead with only two dependencies (Narwhals and FSSpec)</li> <li>Simple, easy API: Low mental overheads with two simple functions for testing dataframes, and a simple dataclass for results.</li> </ul> <p>Ideally, all data would be usable when you recieve it, but you probably already have figured that's not always the case. That's where data contracts come in.</p> <p>A data contract is an expression of what should be true of some data, such as that it should 'only have columns x and y' or 'the values of column a should never exceed 1'. Wimsey is a library built to run these contracts on a dataframe during python runtime.</p> <p>Additionally, Wimsey has tools to help you generate sensible tests from a data sample</p> <p>Wimsey is built on top of the awesome Narwhals and natively supports any dataframes that Narwhal's does. At the time of writing, that includes Polars, Pandas, Arrow, Dask, Rapids and Modin.</p> <p>If you're looking to get a quick feel for Wimsey, check out the quick start documentation</p>"},{"location":"building-tests/","title":"Building Tests","text":"<p>Alongside running tests, Wimsey also has some functions to aid building tests. This can be useful if you want to automagically create some sensible initial tests for multiple datasets, without needing to type them out by hand, or create them manually in code.</p> <p>As with the rest of Wimsey, your own dataframe engine will be used to sample the relevant statistics. Wimsey can either generate starter tests from a list of samples or it can use sampling with replacement to generate samples for you from a single dataframe. If you use the latter, note that Wimsey will need to evaluate each sample individually so if you are using a lazy framework such as Polars' LazyFrames, Dask or Modin you will likely want to collect your results first, or implement a caching mechanism to avoid unnecessary repeated computation.</p>"},{"location":"building-tests/#what-is-margin","title":"What is margin?","text":"<p>You'll see the keyword margin throughout Wimsey test building, it's worth explaining here first.</p> <p>Margin is the amount of extra allowance tests give, based on the sample. For instance if Wimsey has three samples, with a \"column_a\" maximum of 1, 2 and 3, rather than creating a test for the maximum being 3 (the highest value seen in the samples), Wimsey will allow an amount of 'give' for the tests.</p> <p>This is based on the standard deviation of the statistical metric, and for the above example would be 1, meaning that Wimsey would build a test that expects the maximum to be less than or equal to 4.</p> <p>If this is all giberish to you, don't worry, the 'margin' keyword defaults to 1, which is often a sensible choice, if you find that Wimsey is creating to strict tests, bump it up slightly, if tests are too lax, you can reduce margin to a smaller positive number.</p> <p>Setting <code>margin</code> to a negative value means that your creating a test that your given sample would fail, and while supported, is unlikely to be what you're looking to do.</p>"},{"location":"building-tests/#from-sampling","title":"From Sampling","text":"<p>From a single dataframe, Wimsey will sample with replacement to build a starter test. The <code>samples</code> keyword specifies the number of times you want Wimsey to build a sample, while <code>n</code> or <code>fraction</code> tell Wimsey the size (in rows) or fraction (as a float) of the sample to take. Note that you can't supply both n AND fraction keywords to Wimsey.</p> <p>Wimsey has a <code>starter_tests_from_sampling</code> function, and a <code>save_starter_tests_from_sampling</code> function dependent on whether you're intending to return the tests as a dictionary, or save them to a file. <code>save_starter_tests_from_sampling</code> takes the exact same arguments, but with the addition of a <code>path</code> and an optional <code>storage_options</code> argument.</p> starter_tests_from_samplingsave_starter_tests_from_sampling <pre><code>import polars as pl\nfrom wimsey.profile import starter_tests_from_sampling\n\ndf = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [\"cool\", \"bat\", \"hat\"]})\ntests: list[dict] = starter_tests_from_sampling(df, samples=5_000, n=2, margin=3)\n</code></pre> <pre><code>import pandas as pd\nfrom wimsey.profile import starter_tests_from_sampling\n\ndf = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [\"cool\", \"bat\", \"hat\"]})\ntests: list[dict] = save_starter_tests_from_sampling(\n    path=\"my-first-test.json\",\n    df=df,\n    samples=5_000,\n    fraction=0.5,\n    margin=3,\n)\n</code></pre>"},{"location":"building-tests/#from-samples","title":"From Samples","text":"<p>From a list (or other iterable such as a generate) of supported dataframes, Wimsey will produce a list of passing tests.</p> <p>Wimsey has a <code>starter_tests_from_samples</code> function, and a <code>save_starter_tests_from_samples</code> function dependent on whether you're intending to return the tests as a dictionary, or save them to a file. <code>save_starter_tests_from_samples</code> takes the exact same arguments, but with the addition of a <code>path</code> and an optional <code>storage_options</code> argument.</p> starter_tests_from_samplessave_starter_tests_from_samples <pre><code>from glob import glob\n\nimport pandas as pd\nfrom wimsey.profile import starter_tests_from_samples\n\ndfs = [pd.read_csv(i) for i in glob(\"folder/of/samples/*.csv\")]\ntests: list[dict] = starter_tests_from_samples(dfs, margin=1.5)\n</code></pre> <pre><code>from glob import glob\n\nimport polars as pl\nfrom wimsey.profile import save_starter_tests_from_samples\n\nfrom config import my_storage_options\n\nsave_starter_tests_from_samples(\n    path=\"s3://test-store/cooltest.yaml\",\n    samples=[pl.read_parquet(i) for i in glob(\"folder/of/samples/*.parquet\")],\n    margin=0.8,\n    storage_options=my_storage_options,\n)\n</code></pre>"},{"location":"motivation/","title":"Motivation","text":"<p>Wimsey is designed to be a data contracts library a lot like Soda or Great Expectations. Rather than aiming to provide new functionality, it's primary motivation is to be as lightweight as possible, and, by focusing on dataframes, allow data tests to be evaluated natively and efficiently.</p> <p>It's probably a good fit for you if:</p> <ul> <li>\u2705 You're working with dataframes in python (via Pandas, Polars, Dask, Modin, etc)</li> <li>\u2705 You want to carry out data testing with minimal overheads</li> <li>\u2705 You want to minimise your overall dependencies</li> <li>\u2705 Have an existing metadata format that you want to integrate tests into</li> </ul> <p>It might not work for you if:</p> <ul> <li>\u274c You're wanting to test SQL data without ingesting into python</li> <li>\u274c You want a data contracts solution that also provides a business user facing GUI</li> </ul>"},{"location":"motivation/#how-small-is-wimsey","title":"How small is Wimsey?","text":"<p>The answer is very. To give you a picture of comparison to alternative tools by size, here's a comparions of virtual environment sizes based on libaries + their dependencies*.</p> <p>{   \"description\": \"A simple bar chart with embedded data.\",   \"data\": {\"url\" : \"assets/raw-size.csv\"},   \"mark\": {\"type\": \"bar\", \"tooltip\": true},   \"encoding\": {     \"x\": {\"field\": \"Package\", \"type\": \"nominal\", \"axis\": {\"labelAngle\": 0}},     \"y\": {\"field\": \"Installation Size (MB)\", \"type\": \"quantitative\"}   } }</p> <p>It's worth bearing in mind that some of these dependencies might be ones you already need to have installed.</p> <p>* Note that soda is a little unusual here, since <code>soda-core</code> is very small (around 2x Wimsey's size), but also requires additional components to work with different data types.</p>"},{"location":"motivation/#how-fast-is-wimsey","title":"How fast is Wimsey?","text":"<p>That's a very big it depends. Wimsey executes tests in your own dataframe library so performance will match your library of choice, if you're using Modin or Dask, Wimsey will be able to operate over large distributed datasets, if you're using Polars, Wimsey will be blazingly fast.</p> <p>Narwhals operates natively on dataframes with minimal overhead so you should expect to see performant operations. Additionally, if you were previously needing to convert, or sample data into another format, you'll no longer need to carry this step out, saving you more runtime.</p>"},{"location":"possible-tests/","title":"Test Catalogue \ud83e\uddea","text":"<p>This documentation is intended as an exaustive list of possible tests within Wimsey. Note that examples given intentionally use all possible keywords for demonstrative purposes. This isn't required, and you can give as many or as few keywords as you like with the exception of where <code>column</code> is required.</p>"},{"location":"possible-tests/#mean_should","title":"mean_should","text":"<p>Test that column mean is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\ntest: mean_should\n</code></pre> <pre><code>{\n  \"test\": \"mean_should\",\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import mean_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[mean_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#min_should","title":"min_should","text":"<p>Test that column min is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\ntest: min_should\n</code></pre> <pre><code>{\n  \"test\": \"min_should\",\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import min_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[min_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#max_should","title":"max_should","text":"<p>Test that column max is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\ntest: max_should\n</code></pre> <pre><code>{\n  \"test\": \"max_should\",\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import max_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[max_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#std_should","title":"std_should","text":"<p>Test that column std is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\ntest: std_should\n</code></pre> <pre><code>{\n  \"test\": \"std_should\",\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import std_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[std_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#null_count_should","title":"null_count_should","text":"<p>Test that column null_count is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\ntest: null_count_should\n</code></pre> <pre><code>{\n  \"test\": \"null_count_should\",\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import null_count_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[null_count_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#count_should","title":"count_should","text":"<p>Test that column count is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\ntest: count_should\n</code></pre> <pre><code>{\n  \"test\": \"count_should\",\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import count_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[count_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#null_percentage_should","title":"null_percentage_should","text":"<p>Test that column null_percentage is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\ntest: null_percentage_should\n</code></pre> <pre><code>{\n  \"test\": \"null_percentage_should\",\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import null_percentage_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[null_percentage_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#columns_should","title":"columns_should","text":"<p>Test column names match up with expected values</p> yamljsonpython <pre><code>be:\n- column_a\n- column_b\nhave:\n- column_a\nnot_have:\n- column_c\ntest: columns_should\n</code></pre> <pre><code>{\n  \"test\": \"columns_should\",\n  \"have\": [\n    \"column_a\"\n  ],\n  \"not_have\": [\n    \"column_c\"\n  ],\n  \"be\": [\n    \"column_a\",\n    \"column_b\"\n  ]\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import columns_should\n\nkeywords = {\n  \"have\": [\n    \"column_a\"\n  ],\n  \"not_have\": [\n    \"column_c\"\n  ],\n  \"be\": [\n    \"column_a\",\n    \"column_b\"\n  ]\n}\n\nresult = test(df, contract=[columns_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#type_should","title":"type_should","text":"<p>Test column type matches up with expected value. Note that this will expect polars style types, although does not require that they be case sensitive. For example, if testing a pandas dataframe for integer type, specify \"int64\" rather than, say, \"int64[pyarrow]\" or otherwise.</p> yamljsonpython <pre><code>be: int64\nbe_one_of:\n- int64\n- float64\ncolumn: column_a\nnot_be: string\ntest: type_should\n</code></pre> <pre><code>{\n  \"test\": \"type_should\",\n  \"column\": \"column_a\",\n  \"be\": \"int64\",\n  \"not_be\": \"string\",\n  \"be_one_of\": [\n    \"int64\",\n    \"float64\"\n  ]\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import type_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"be\": \"int64\",\n  \"not_be\": \"string\",\n  \"be_one_of\": [\n    \"int64\",\n    \"float64\"\n  ]\n}\n\nresult = test(df, contract=[type_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#row_count_should","title":"row_count_should","text":"<p>Test that dataframe row count is within designated range</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ntest: row_count_should\n</code></pre> <pre><code>{\n  \"test\": \"row_count_should\",\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500,\n  \"be_exactly\": 300\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import row_count_should\n\nkeywords = {\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500,\n  \"be_exactly\": 300\n}\n\nresult = test(df, contract=[row_count_should(**keywords)])\n</code></pre>"},{"location":"possible-tests/#average_difference_from_other_column_should","title":"average_difference_from_other_column_should","text":"<p>Test that the average difference between column and other column are within designated bounds.</p> yamljsonpython <pre><code>be_exactly: 300\nbe_greater_than: 500\nbe_greater_than_or_equal_to: 500\nbe_less_than: 500\nbe_less_than_or_equal_to: 300\ncolumn: column_a\nother_column: column_b\ntest: average_difference_from_other_column_should\n</code></pre> <pre><code>{\n  \"test\": \"average_difference_from_other_column_should\",\n  \"column\": \"column_a\",\n  \"other_column\": \"column_b\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n</code></pre> <pre><code>from wimsey import test\nfrom wimsey.tests import average_difference_from_other_column_should\n\nkeywords = {\n  \"column\": \"column_a\",\n  \"other_column\": \"column_b\",\n  \"be_exactly\": 300,\n  \"be_less_than\": 500,\n  \"be_less_than_or_equal_to\": 300,\n  \"be_greater_than\": 500,\n  \"be_greater_than_or_equal_to\": 500\n}\n\nresult = test(df, contract=[average_difference_from_other_column_should(**keywords)])\n</code></pre>"},{"location":"quick-start/","title":"Quick Start","text":"<p>As an example, let's work through a simple example, and imagine we recieve \"top-5-sleuths.csv\" daily, over sftp. It's meant to look something like this:</p> first_name last_name rating cases_solved Peter Wimsey 9 11 Jane Marple 9 12 Father Brown 7 53 Hercule Poirot 10 33 Beatrice Bradley 8 66 <p>It's meant to contain the top 5 sleuths, only sometimes, it has the wrong number of entries; othertimes first names are missing; and whilst ratings should be out of 10, sometimes they are over that. To make things worse every now and then, someone puts \"lots\" into <code>cases_solved</code> meaning it's no longer a number, and that causes all kinds of trouble.</p>"},{"location":"quick-start/#writing-tests","title":"Writing Tests","text":"<p>We can convert those concerns we just mentioned into four tests to carry out on our dataset:</p> <ul> <li>The row count should be 5</li> <li><code>first_name</code> should never be null</li> <li><code>rating</code> should be be less than 10</li> <li><code>cases_solved</code> should be a number</li> </ul> <p>We can test for a lot more than that, but that works for our example. Our first move is to write this out as a \"contract\". This can be a yaml or json file, or alternatively, we can code it directly into python.</p> sleuth-checks.yamlsleuth-checks.jsonsleuth_checks.py <pre><code>- test: row_count_should\n  be_exactly: 5\n- column: first_name\n  test: null_percentage_should\n  be_exactly: 0\n- column: rating\n  test: max_should\n  be_less_than_or_equal_to: 10\n- column: cases_solved\n  test: type_should\n  be_one_of:\n    - int64\n    - float64\n</code></pre> <p>Note you'll need <code>pyyaml</code> installed to support reading yaml</p> <pre><code>[\n  {\n    \"test\": \"row_count_should\",\n    \"be_exactly\": 5\n  },\n  {\n    \"column\": \"first_name\",\n    \"test\": \"null_percentage_should\",\n    \"be_exactly\": 0\n  },\n  {\n    \"column\": \"rating\",\n    \"test\": \"max_should\",\n    \"be_less_than_or_equal_to\": 10\n  },\n  {\n    \"column\": \"cases_solved\",\n    \"test\": \"type_should\",\n    \"be_one_of\": [\"int64\", \"float64\"]\n]\n</code></pre> <pre><code>from wimsey import tests\n\nchecks = [\n  tests.row_count_should(be_exactly=5),\n  tests.null_percentage_should(column=\"first_name\", be_exactly=0),\n  tests.max_should(column=\"rating\", be_less_than_or_equal_to=10),\n  tests.type_should(column=\"cases_solved\", be_one_of=[\"int64\", \"float64]),\n]\n</code></pre> <p>See Possible Tests for a full catalogue of runnable tests and their configurations.</p>"},{"location":"quick-start/#executing-tests","title":"Executing Tests","text":"<p>Now that we've written out tests, we just need to actually run them on the actual data. There's two functions <code>wimsey</code> gives you to carry out checks: <code>validate</code> and <code>test</code>. These both carry out checks in the same way, but behave slightly differently based on the results.</p> <ul> <li><code>test</code> will return a <code>FinalResult</code> type of object. It's a dataclasses containing a <code>success</code> boolean, alongside further details on the individual tests in a <code>results</code> lists.</li> <li><code>validate</code> will run the checks and then just return the initial dataframe assuming everything passed. If any tests failed, it'll stop execution and throw a <code>DataValidationException</code>.</li> </ul> <p>These are designed to cover a couple different use cases, <code>test</code> will provide more details if you want to dig into problems in a dataset, whilst <code>validate</code> is helpful if you just want to use <code>wimsey</code> as a \"guard\" to catch bad data from being processed.</p> <p>We'll cover <code>test</code> first, it's called the same regardless of what type your dataframe is:</p> using sleuth-checks.yamlusing sleuth-checks.jsonusing sleuth_checks.py <pre><code>from wimsey import test\n\nresult = test(df, contract=\"sleuth-checks.yaml\")\nif result.success:\n  print(\"Everything is as expected! \ud83d\ude4c\")\nelse:\n  print(\"Uh-oh, something's up! \ud83d\ude2c\")\n  print([i for i in result.results if not i.success])\n</code></pre> <p>Note you'll need <code>pyyaml</code> installed to support reading yaml</p> <pre><code>from wimsey import test\n\nresult = test(df, contract=\"sleuth-checks.json\")\nif result.success:\n  print(\"Everything is as expected! \ud83d\ude4c\")\nelse:\n  print(\"Uh-oh, something's up! \ud83d\ude2c\")\n  print([i for i in result.results if not i.success])\n</code></pre> <pre><code>from wimsey import test\nfrom sleuth_checks import checks\n\nresult = test(df, contract=checks)\nif result.success:\n  print(\"Everything is as expected! \ud83d\ude4c\")\nelse:\n  print(\"Uh-oh, something's up! \ud83d\ude2c\")\n  print([i for i in result.results if not i.success])\n</code></pre> <p>Wimsey uses fsspec under the hood, so configs can be from any filesystem supported by fsspec (such as S3, SSH, Azure, Google Cloud etc) - use the fsspec prefix and pass in the appropriate storage options using <code>test</code>'s <code>storage_options</code> keyword. See fsspec documentation for more details on this.</p> <p>Validate, will run tests in the exact same way as <code>test</code>, but simply raises an error if data fails expectations. This, in conjunction with Wimsey's compatibility with multiple dataframe types can make it a convenient tool for providing guarantees in a data pipeline.</p> pandaspolarsdaskpyarrow <pre><code>import pandas as pd\nfrom wimsey import validate\n\nfrom settings import sleuth_storage_options\n\ntop_sleuth: str = (\n  pd.read_csv(\n    \"sshfs://sleuthwatch/top-5-sleuths.csv\",\n    storage_options=sleuth_storage_options,\n  )\n  .pipe(validate, \"sleuth-checks.json\")  # &lt;- this is the wimsey bit\n  .assign(name=lambda df: df[\"first_name\"] + df[\"last_name\"])\n  .sort_values(\"rating\", ascending=False)\n  [\"name\"][0]\n)\n\nprint(f\"{top_sleuth} is the best sleuth!\")\n</code></pre> <pre><code>import polars as pl\nfrom wimsey import validate\n\nfrom settings import sleuth_storage_options\n\ntop_sleuth: str = (\n  pl.read_csv(\n    \"sshfs://sleuthwatch/top-5-sleuths.csv\",\n    storage_options=storage_options,\n  )\n  .pipe(validate, \"sleuth-checks.json\")  # &lt;- this is the wimsey bit\n  .with_columns(name=pl.col(\"first_name\") + \" \" + pl.col(\"last_name\"))\n  .sort(\"rating\", descending=True)\n  .select(\"name\")\n  .to_series()[0]\n)\n\nprint(f\"{top_sleuth} is the best sleuth!\")\n</code></pre> <pre><code>import dask.dataframe as dd\nfrom wimsey import validate\n\nfrom settings import sleuth_storage_options\n\ntop_sleuth: str = (\n  dd.read_csv(\n    \"sshfs://sleuthwatch/top-5-sleuths.csv\",\n    storage_options=sleuth_storage_options,\n  )\n  .pipe(validate, \"sleuth-checks.json\")  # &lt;- this is the wimsey bit\n  .assign(name=lambda df: df[\"first_name\"] + \" \" + df[\"last_name\"])\n  .sort_values(\"rating\", ascending=False)\n  [\"name\"]\n  .compute()[0]\n)\n\nprint(f\"{top_sleuth} is the best sleuth!\")\n</code></pre> <pre><code>from pyarrow import compute, csv\nfrom wimsey import validate\n\nfrom settings import download_sleuth_file\n\ndownload_sleuth_file(to=\"local-5-sleuths.csv\")\ndf = csv.read_csv(\"local-5-sleuths.csv\")\nvalidate(df, \"sleuth-checks.json\")  # &lt;- this is the wimsey bit\nname = compute.binary_join_element_wise(df[\"first_name\"], df[\"last_name\"], \" \")\ndf = df.append(\"name\", name).sort_by(\"rating\")\ntop_sleuth = str(df[\"name\"][-1])\n\nprint(f\"{top_sleuth} is the best sleuth!\")\n</code></pre> <p>And that's it for testing, to keep things simple <code>validate</code> and <code>test</code> are the only public-intended functions in Wimsey, aside from test creation, which is covered further in the possible tests section.</p> <p>Wimsey also support generating tests, see the building tests section for how to get started.</p>"}]}